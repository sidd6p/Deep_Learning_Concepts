{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/siddp6/mlp-mnist-1?scriptVersionId=138654024\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Introduction\n\nIn this project, you will build a neural network of your own design to evaluate the MNIST dataset.\n\nSome of the benchmark results on MNIST include can be found [on Yann LeCun's page](http://yann.lecun.com/exdb/mnist/) and include:\n\n88% [Lecun et al., 1998](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n95.3% [Lecun et al., 1998](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n99.65% [Ciresan et al., 2011](http://people.idsia.ch/~juergen/ijcai2011.pdf)\n\nMNIST is a great dataset for sanity checking your models, since the accuracy levels achieved by large convolutional neural networks and small linear models are both quite high. This makes it important to be familiar with the data.\n\n## Imports","metadata":{}},{"cell_type":"code","source":"## This cell contains the essential imports you will need – DO NOT CHANGE THE CONTENTS! ##\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom torch.utils.data import DataLoader\nfrom time import time\nfrom torchvision import datasets","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load the Dataset\n\nSpecify your transforms as a list if you intend to .\nThe transforms module is already loaded as `transforms`.\n\nMNIST is fortunately included in the torchvision module.\nThen, you can create your dataset using the `MNIST` object from `torchvision.datasets` ([the documentation is available here](https://pytorch.org/vision/stable/datasets.html#mnist)).\nMake sure to specify `download=True`! \n\nOnce your dataset is created, you'll also need to define a `DataLoader` from the `torch.utils.data` module for both the train and the test set.","metadata":{}},{"cell_type":"code","source":"import torchvision\nimport torchvision.transforms as transforms\n\nclass MNIST_Transformer(object):\n    def __call__(self, data):\n        data = transforms.ToTensor()(data)\n        data = transforms.Normalize((0.5,), (0.5,))(data)\n        \n        return data\n\ntransform = transforms.Compose([\n    MNIST_Transformer()\n])\n\n\nroot='data'\ntrain_set = datasets.MNIST(root=root, download=True, train=True, transform=transform)\ntest_set = datasets.MNIST(root=root, download=True, train=False, transform=transform)\n\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Justify your preprocessing\n\nIn your own words, why did you choose the transforms you chose? If you didn't use any preprocessing steps, why not?","metadata":{}},{"cell_type":"markdown","source":"I chose the following transforms for preprocessing the MNIST dataset:\n\n**transforms.ToTensor()**: This transform converts the images from the MNIST dataset, which are in the form of PIL images, into PyTorch tensors. Working with tensors is essential in PyTorch for efficient computation and automatic differentiation during the training process.\n\n**transforms.Normalize((0.5,), (0.5,))**: This transform normalizes the pixel values of the images. The MNIST dataset contains grayscale images with pixel values ranging from 0 to 255. By applying this normalization, we scale the pixel values to be in the range of [-1, 1]. This standardization helps the model converge faster during training, as it prevents gradient explosions or vanishing due to large discrepancies in pixel values.","metadata":{}},{"cell_type":"markdown","source":"## Explore the Dataset\nUsing matplotlib, numpy, and torch, explore the dimensions of your data.\n\nYou can view images using the `show5` function defined below – it takes a data loader as an argument.\nRemember that normalized images will look really weird to you! You may want to try changing your transforms to view images.\nTypically using no transforms other than `toTensor()` works well for viewing – but not as well for training your network.\nIf `show5` doesn't work, go back and check your code for creating your data loaders and your training/test sets.","metadata":{}},{"cell_type":"code","source":"# Explore dataset properties\ndef dataset_properties(data, name):\n    print(f\"{name} Set:\")\n    print(\"Number of samples:\", len(data))\n    print(f\"Number of batches {name}_loader): {len(data)}\")\n    print(\"Data shape (single sample):\", data[0][0].shape)\n    print(\"Label of the first sample:\", data[0][1])\n    print(\"\\n\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_properties(train_set, \"train\")\ndataset_properties(test_set, \"test\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## This cell contains a function for showing 5 images from a dataloader – DO NOT CHANGE THE CONTENTS! ##\ndef show5(img_loader):\n    dataiter = iter(img_loader)\n    \n    batch = next(dataiter)\n    labels = batch[1][0:5]\n    images = batch[0][0:5]\n    for i in range(5):\n        print(int(labels[i].detach()))\n    \n        image = images[i].numpy()\n        plt.imshow(image.T.squeeze().T)\n        plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Explore data\nshow5(train_loader)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build your Neural Network\nUsing the layers in `torch.nn` (which has been imported as `nn`) and the `torch.nn.functional` module (imported as `F`), construct a neural network based on the parameters of the dataset.\nUse any architecture you like. \n\n*Note*: If you did not flatten your tensors in your transforms or as part of your preprocessing and you are using only `Linear` layers, make sure to use the `Flatten` layer in your network!","metadata":{}},{"cell_type":"code","source":"class MNIST_NN(nn.Module):\n    def __init__(self):\n        super(MNIST_NN, self).__init__()\n        self.flatten = nn.Flatten()\n        self.fc1 = nn.Linear(784, 128)\n        self.fc2 = nn.Linear(128, 64)\n        self.fc3 = nn.Linear(64, 10)\n    \n    def forward(self, x):\n        x = self.flatten(x)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Specify a loss function and an optimizer, and instantiate the model.\n\nIf you use a less common loss function, please note why you chose that loss function in a comment.","metadata":{}},{"cell_type":"code","source":"model = MNIST_NN()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.01)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the MNIST dataset, which is a classification problem, we commonly use the CrossEntropyLoss as the loss function. The CrossEntropyLoss combines the Softmax activation and the negative log-likelihood loss, making it suitable for multi-class classification tasks like MNIST.\n\nFor the optimizer, we'll use the stochastic gradient descent (SGD) optimizer, which is a simple and widely used optimization algorithm for training neural networks. It updates the model parameters based on the gradients of the loss with respect to the parameters, scaled by a learning rate.","metadata":{}},{"cell_type":"markdown","source":"## Running your Neural Network\nUse whatever method you like to train your neural network, and ensure you record the average loss at each epoch. \nDon't forget to use `torch.device()` and the `.to()` method for both your model and your data if you are using GPU!\n\nIf you want to print your loss **during** each epoch, you can use the `enumerate` function and print the loss after a set number of batches. 250 batches works well for most people!","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, train_loader, criterion, optimizer, num_epochs=10, print_every=250):\n    model.train()\n    model.to(device)\n    \n    loss_values = []\n    \n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        \n        for batch_idx, (inputs, targets) in enumerate(train_loader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            \n            # Zero the parameter gradients\n            optimizer.zero_grad()\n            \n            # Forward pass\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            \n            # Backward pass and optimization\n            loss.backward()\n            optimizer.step()\n            \n            # Record the loss\n            running_loss += loss.item()\n            \n            # Print the loss every print_every batches\n            if batch_idx % print_every == print_every - 1:\n                avg_loss = running_loss / print_every\n                print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {avg_loss:.4f}\")\n                running_loss = 0.0\n        \n        # Calculate the average loss for the epoch\n        avg_epoch_loss = running_loss / len(train_loader)\n        loss_values.append(avg_epoch_loss)\n    \n    print(\"Training finished.\")\n    return loss_values","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_values = train_model(model, train_loader, criterion, optimizer, num_epochs=5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot the training loss (and validation loss/accuracy, if recorded).","metadata":{}},{"cell_type":"code","source":"def plot_loss(loss_values):\n    plt.figure(figsize=(8, 5))\n    plt.plot(range(1, len(loss_values)+1), loss_values, label='Training Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.title('Training Loss')\n    plt.legend()\n    plt.grid(True)\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_loss(loss_values)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing your model\nUsing the previously created `DataLoader` for the test set, compute the percentage of correct predictions using the highest probability prediction. \n\nIf your accuracy is over 90%, great work, but see if you can push a bit further! \nIf your accuracy is under 90%, you'll need to make improvements.\nGo back and check your model architecture, loss function, and optimizer to make sure they're appropriate for an image classification task.","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, test_loader):\n    # Evaluate the model on the test set\n    model.eval()  # Set the model to evaluation mode\n    correct = 0\n    total = 0\n\n    with torch.no_grad():  # Disable gradient tracking for evaluation\n        for data in test_loader:\n            images, labels = data\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    test_accuracy = 100 * correct / total\n    \n    return test_accuracy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Test Accuracy: {evaluate_model(model, test_loader):.2f}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Improving your model\n\nOnce your model is done training, try tweaking your hyperparameters and training again below to improve your accuracy on the test set!","metadata":{}},{"cell_type":"code","source":"# Train the improved-model\nnum_epochs = 10\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nloss_values = train_model(model, train_loader, criterion, optimizer, num_epochs=num_epochs)\nplot_loss(loss_values)\nprint(f\"Test Accuracy: {evaluate_model(model, test_loader):.2f}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Optimiser**: Adam is an adaptive learning rate optimization algorithm that combines the advantages of both AdaGrad and RMSprop. It adapts the learning rates of each parameter during training based on the historical gradients. Adam often converges faster than traditional SGD and can handle sparse gradients well, making it a popular choice for various deep learning tasks.\n\n**epochs**: Increasing the number of epochs, to as we do not see any overfitting in graph.","metadata":{}},{"cell_type":"markdown","source":"## Saving your model\nUsing `torch.save`, save your model for future loading.","metadata":{}},{"cell_type":"code","source":"# Save the improved model to a file\ntorch.save(model.state_dict(), 'model_state.pt')\nprint(\"Improved model saved successfully.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scripted = torch.jit.script(model)\ntorch.jit.save(scripted, 'model_script.pt')","metadata":{"execution":{"iopub.status.busy":"2023-07-23T11:20:26.086104Z","iopub.execute_input":"2023-07-23T11:20:26.086995Z","iopub.status.idle":"2023-07-23T11:20:26.64026Z","shell.execute_reply.started":"2023-07-23T11:20:26.086942Z","shell.execute_reply":"2023-07-23T11:20:26.63824Z"},"trusted":true},"execution_count":null,"outputs":[]}]}