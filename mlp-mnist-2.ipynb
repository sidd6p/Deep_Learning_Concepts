{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/siddp6/mlp-mnist-2?scriptVersionId=138653910\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Multi-Layer Perceptron, MNIST\n---\nIn this notebook, we will train an MLP to classify images from the [MNIST database](http://yann.lecun.com/exdb/mnist/) hand-written digit database.\n\nThe process will be broken down into the following steps:\n>1. Load and visualize the data\n2. Define a neural network\n3. Train the model\n4. Evaluate the performance of our trained model on a test dataset!\n\nBefore we begin, we have to import the necessary libraries for working with data and PyTorch, as well as a few more for convenience.","metadata":{}},{"cell_type":"code","source":"import torch\nimport multiprocessing\nimport numpy as np\nfrom tqdm import tqdm\n","metadata":{"execution":{"iopub.status.busy":"2023-08-01T19:49:07.60275Z","iopub.execute_input":"2023-08-01T19:49:07.603199Z","iopub.status.idle":"2023-08-01T19:49:09.410751Z","shell.execute_reply.started":"2023-08-01T19:49:07.603153Z","shell.execute_reply":"2023-08-01T19:49:09.409611Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"---\n## Load and Visualize the [Data](http://pytorch.org/docs/stable/torchvision/datasets.html)\n\nDownloading may take a few moments, and you should see your progress as the data is loading. You may also choose to change the `batch_size` if you want to load more data at a time.\n\nThis cell will create DataLoaders for each of our datasets.","metadata":{}},{"cell_type":"markdown","source":"The code snippet you provided is using the `urllib` module from the `six.moves` package, which is a compatibility module used to handle differences between Python 2 and Python 3. In this code, it sets a custom User-Agent header and installs an opener with the custom User-Agent for all future urllib requests.\n\nHere's what each part of the code does:\n\n1. `from six.moves import urllib`: Import the `urllib` module from the `six.moves` package. In Python 2, `urllib` was split into several modules, and `six.moves` provides a consistent way to access these modules across Python 2 and Python 3.\n\n2. `opener = urllib.request.build_opener()`: This line creates an opener object using the `build_opener()` method from `urllib.request`. An opener is an object that manages the connection to a URL and can be used to open URLs with different settings.\n\n3. `opener.addheaders = [('User-agent', 'Mozilla/5.0')]`: This line adds a custom header to the opener. The header being added is the \"User-Agent\" header, which is often used to identify the client (in this case, 'Mozilla/5.0' represents a common User-Agent for Mozilla Firefox). Setting a custom User-Agent can be useful in some cases when interacting with web servers that require specific user-agent information.\n\n4. `urllib.request.install_opener(opener)`: This line installs the custom opener as the default opener for all future `urllib.request` calls. This means that any subsequent HTTP requests made using `urllib` will use this custom opener with the added User-Agent header.\n\nAfter running this code, any subsequent HTTP requests made using `urllib` will include the specified User-Agent header. For example, if you use `urllib.request.urlopen()` to open a URL, the custom User-Agent header will be sent along with the request. This can be useful when you need to mimic a specific user agent or when some websites might block requests from specific User-Agents.\n\nRemember that using a custom User-Agent header might violate some website's terms of service, so it's essential to ensure that you're using it responsibly and in compliance with the website's policies.\n","metadata":{}},{"cell_type":"code","source":"from six.moves import urllib\n\nopener = urllib.request.build_opener()\nopener.addheaders = [('User-agent', 'Mozilla/5.0')]\nurllib.request.install_opener(opener)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T19:49:09.413016Z","iopub.execute_input":"2023-08-01T19:49:09.413564Z","iopub.status.idle":"2023-08-01T19:49:09.419798Z","shell.execute_reply.started":"2023-08-01T19:49:09.413534Z","shell.execute_reply":"2023-08-01T19:49:09.418892Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from torchvision import datasets\nimport torchvision.transforms as transforms\n\n# number of sub-process to load the data\n# set to the number of CPUs avaliable\nnum_workers = multiprocessing.cpu_count()\n\n# number of sample per batch ot load\nbatch_size = int(48000 / 5)\n\ntransform = transforms.Compose([\n    # input: np.array or PIL image with range 0-255\n    # transform: float tensor with range 0.0 - 1.0\n    transforms.ToTensor(),\n    \n    # transform: float tensor with range -1.0 - 1.0\n    # (better for activation like Relu)\n    transforms.Normalize((0.5), (0.5)),\n])\n","metadata":{"execution":{"iopub.status.busy":"2023-08-01T19:49:09.421235Z","iopub.execute_input":"2023-08-01T19:49:09.421828Z","iopub.status.idle":"2023-08-01T19:49:09.555026Z","shell.execute_reply.started":"2023-08-01T19:49:09.421797Z","shell.execute_reply":"2023-08-01T19:49:09.554131Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_val_data = datasets.MNIST(root = \"data\", train=True, download=True, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T19:49:09.557459Z","iopub.execute_input":"2023-08-01T19:49:09.557806Z","iopub.status.idle":"2023-08-01T19:49:09.641469Z","shell.execute_reply.started":"2023-08-01T19:49:09.557776Z","shell.execute_reply":"2023-08-01T19:49:09.640641Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"In the specific context of the code snippet you provided, `torch.utils.data.random_split()` uses the random number generator (`generator`) to perform the random split of the dataset (`train_val_data`). By setting the same fixed seed (42) each time the code runs, the split will be consistent and reproducible across different runs.\n\nFor example, if you run the script multiple times with the same seed (42), you will get the same training and validation subsets split from the `train_val_data`, making it easier to compare results and analyze model performance.\n","metadata":{}},{"cell_type":"markdown","source":"- 'shuffle=True': This shuffles the data before each epoch during training to introduce randomness and improve convergence.\n\n- 'num_workers': Set the number of worker processes to load data in parallel. This can speed up data loading for large datasets.\n","metadata":{}},{"cell_type":"code","source":"# Split into tarin and Validation\ntrain_len = int(len(train_val_data)*.80)\nval_len = int(len(train_val_data)*.20)\n\ntrain_subset, val_subset = torch.utils.data.random_split(\n    train_val_data, [train_len, val_len], generator=torch.Generator().manual_seed(42)\n)\n\ntrain_loader = torch.utils.data.DataLoader(\ndataset = train_subset, shuffle=True, batch_size=batch_size, num_workers=num_workers\n)\n\nval_loader = torch.utils.data.DataLoader(\ndataset=val_subset, shuffle=False, batch_size=batch_size, num_workers=num_workers\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T19:49:09.642991Z","iopub.execute_input":"2023-08-01T19:49:09.643587Z","iopub.status.idle":"2023-08-01T19:49:09.657703Z","shell.execute_reply.started":"2023-08-01T19:49:09.643557Z","shell.execute_reply":"2023-08-01T19:49:09.656321Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Get test data\ntest_data = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\ntest_loader = torch.utils.data.DataLoader(\n    test_data, batch_size=batch_size, num_workers=num_workers\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T19:49:09.659442Z","iopub.execute_input":"2023-08-01T19:49:09.65982Z","iopub.status.idle":"2023-08-01T19:49:09.678319Z","shell.execute_reply.started":"2023-08-01T19:49:09.659777Z","shell.execute_reply":"2023-08-01T19:49:09.677167Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(f\"Data: {len(train_val_data)}\")\nprint(f\"Data for train: {len(train_subset)}\")\nprint(f\"Total batches in train loader: {len(train_loader)}\")\nprint(f\"Total images in one batch: {len(train_subset)/len(train_loader)}\")\nprint(\"\\n\")\n\nbatch_1 = next(iter(train_loader))\nprint(f\"Each batch has {len(batch_1)} component, image and label\")\nprint(\"\\n\")\n\nprint(f\"First component has {len(batch_1[0])} images\")\nprint(f\"Second component has {len(batch_1[1])} labels\")\nprint(f\"Shape of first component of each batch {batch_1[0].shape}\")\nprint(f\"Shape of second component of each batch {batch_1[1].shape}\")\n\nprint(\"\\n\")\n\n\n# print(f\"First image from first batch is {batch_1[0][0]} and lable is {batch_1[1][0]}\")\n\nprint(f\"Shape of Image: {batch_1[0][0].shape}\")\nprint(f\"Shape of Label: {batch_1[1][0].shape}\")\nprint(f\"Shape of Image after view function {batch_1[0][0].view(-1, 28*28).shape}\")\nprint(\"\\n\")\n\n\nprint(len(train_loader.dataset))","metadata":{"execution":{"iopub.status.busy":"2023-08-01T19:49:09.679725Z","iopub.execute_input":"2023-08-01T19:49:09.680176Z","iopub.status.idle":"2023-08-01T19:49:15.172963Z","shell.execute_reply.started":"2023-08-01T19:49:09.680136Z","shell.execute_reply":"2023-08-01T19:49:15.17147Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Data: 60000\nData for train: 48000\nTotal batches in train loader: 5\nTotal images in one batch: 9600.0\n\n\nEach batch has 2 component, image and label\n\n\nFirst component has 9600 images\nSecond component has 9600 labels\nShape of first component of each batch torch.Size([9600, 1, 28, 28])\nShape of second component of each batch torch.Size([9600])\n\n\nShape of Image: torch.Size([1, 28, 28])\nShape of Label: torch.Size([])\nShape of Image after view function torch.Size([1, 784])\n\n\n48000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---\n## Define the Network [Architecture](http://pytorch.org/docs/stable/nn.html)\n\n\nThe architecture will be responsible for seeing as input a 784-dim Tensor of pixel values for each image, and producing a Tensor of length 10 (our number of classes) that indicates the class scores for an input image. This particular example uses two hidden layers and dropout to avoid overfitting.","metadata":{}},{"cell_type":"markdown","source":"https://ashwinhprasad.medium.com/pytorch-for-deep-learning-nn-linear-and-nn-relu-explained-77f3e1007dbb","metadata":{}},{"cell_type":"code","source":"model_run_count = 0","metadata":{"execution":{"iopub.status.busy":"2023-08-01T19:49:15.174521Z","iopub.execute_input":"2023-08-01T19:49:15.174923Z","iopub.status.idle":"2023-08-01T19:49:15.180409Z","shell.execute_reply.started":"2023-08-01T19:49:15.174888Z","shell.execute_reply":"2023-08-01T19:49:15.179051Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.layer_1 = nn.Linear(784, 128)\n        self.layer_2 = nn.Linear(128, 64)\n        self.layer_3 = nn.Linear(64, 10)\n        \n        self.Relu = nn.ReLU()\n\n    def forward(self, X):\n        global model_run_count\n        model_run_count += 1\n        X = X.view(-1, 28*28)\n        X = self.Relu(self.layer_1(X))\n        X = self.Relu(self.layer_2(X))\n        X = self.layer_3(X)\n        \n        return X","metadata":{"execution":{"iopub.status.busy":"2023-08-01T19:49:15.181811Z","iopub.execute_input":"2023-08-01T19:49:15.182179Z","iopub.status.idle":"2023-08-01T19:49:15.194096Z","shell.execute_reply.started":"2023-08-01T19:49:15.182151Z","shell.execute_reply":"2023-08-01T19:49:15.192922Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = Net()","metadata":{"execution":{"iopub.status.busy":"2023-08-01T19:49:15.198084Z","iopub.execute_input":"2023-08-01T19:49:15.198649Z","iopub.status.idle":"2023-08-01T19:49:15.206696Z","shell.execute_reply.started":"2023-08-01T19:49:15.19861Z","shell.execute_reply":"2023-08-01T19:49:15.205592Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## (Bonus: visualize the structure of your network)\nYou can visualize your achitecture by using netron.app. Just execute the following cell (which will save the network to a file called \"mnist_network.pt\" in this directory), then download the produced `mnist_network.pt` to your computer. Finally, go to [Netron.app](https://netron.app) and click on `Open Model`, and select the file you just downloaded.","metadata":{}},{"cell_type":"code","source":"# scripted = torch.jit.script(model)\n# torch.jit.save(scripted, \"Net.pt\")","metadata":{"execution":{"iopub.status.busy":"2023-08-01T19:49:15.208157Z","iopub.execute_input":"2023-08-01T19:49:15.208528Z","iopub.status.idle":"2023-08-01T19:49:15.216838Z","shell.execute_reply.started":"2023-08-01T19:49:15.208497Z","shell.execute_reply":"2023-08-01T19:49:15.215937Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"1. `criterion = nn.CrossEntropyLoss()`: \n   - The `CrossEntropyLoss` is a loss function used for multi-class classification tasks.\n   - It combines the softmax activation and the negative log-likelihood loss.\n   - It is suitable for problems where each input belongs to one class among multiple classes.\n\n2. `optimizer = torch.optim.SGD(model.parameters(), lr=0.01)`: \n   - The `SGD` optimizer is used to update the model's parameters during training.\n   - It performs stochastic gradient descent, which updates the parameters based on gradients of the loss.\n   - `model.parameters()` provides the parameters (weights and biases) of the model to be optimized.\n   - `lr=0.01` sets the learning rate, which controls the step size during parameter updates.","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=.01)","metadata":{"execution":{"iopub.status.busy":"2023-08-01T19:49:15.218239Z","iopub.execute_input":"2023-08-01T19:49:15.21879Z","iopub.status.idle":"2023-08-01T19:49:15.229905Z","shell.execute_reply.started":"2023-08-01T19:49:15.218759Z","shell.execute_reply":"2023-08-01T19:49:15.229055Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"---\n## Train the Network\n\nThe steps for training/learning from a batch of data are described in the comments below:\n1. Clear the gradients of all optimized variables\n2. Forward pass: compute predicted outputs by passing inputs to the model\n3. Calculate the loss\n4. Backward pass: compute gradient of the loss with respect to model parameters\n5. Perform a single optimization step (parameter update)\n6. Update average training loss\n\nThe following loop trains for 30 epochs; feel free to change this number. For now, we suggest somewhere between 20-50 epochs. As you train, take a look at how the values for the training loss decrease over time. We want it to decrease while also avoiding overfitting the training data. ","metadata":{}},{"cell_type":"code","source":"# number of epochs to train the model\nn_epochs = 10  # suggest training between 20-50 epochs\nmodel_run_count = 0\nmodel.train() # prep model for training\n\nfor epoch in range(n_epochs):\n    # monitor training loss\n    train_loss = 0.0\n    \n    ###################\n    # train the model #\n    ###################\n    for batch_idx, (data, target) in tqdm(\n            enumerate(train_loader),\n            desc=\"Training\",\n            total=len(train_loader),\n            leave=True,\n            ncols=80,\n        ):\n        \n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        \n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        \n        # calculate the loss\n        loss = criterion(output, target)\n        \n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        \n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        \n        # update running training loss\n        train_loss += loss.item()*data.size(0)\n        \n        print(f\"Train Batch: {batch_idx + 1}/{len(train_loader)}\")\n        \n        print(f\"Total loss in this batch: {loss.item()*data.size(0)}\")\n        print(f\"Number of samples in this batch: {data.size(0)}\")\n        print(f\"Average loss per sample in this batch: {loss.item()}\")\n        print(\"\\n\")\n        \n    # print training statistics \n    # calculate average loss over an epoch\n    avergae_train_loss = train_loss/len(train_loader.dataset)\n    \n    # Validate\n    with torch.no_grad():\n\n        # set the model to evaluation mode\n        model.eval()\n\n        valid_loss = 0.0\n        for batch_idx, (data, target) in tqdm(\n                enumerate(val_loader),\n                desc=\"Validating\",\n                total=len(val_loader),\n                leave=True,\n                ncols=80,\n            ):\n\n            # 1. forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data)  # =\n            # 2. calculate the loss\n            loss = criterion(output, target)  # =\n            \n            # update running training loss\n            valid_loss += loss.item()*data.size(0)\n            \n            print(f\"Val Batch: {batch_idx + 1}/{len(val_loader)}\")\n\n            print(f\"Total val-loss in this batch: {loss.item()*data.size(0)}\")\n            print(f\"Number of samples in this val-batch: {data.size(0)}\")\n            print(f\"Average val-loss per sample in this val-batch: {loss.item()}\")\n            print(\"\\n\")\n\n        # Calculate average validation loss\n        average_valid_loss = valid_loss/len(val_loader.dataset)\n            \n    \n    print(\"\\n######################################\")\n    print(f\"Epoch: {epoch+1} / {n_epochs}\") \n    print(f\"Total loss in this epoch: {train_loss}\")\n    print(f\"Number of samples in this train-epoch: {len(train_loader.dataset)}\")\n    print(f\"Average loss in this epoch: {avergae_train_loss}\")\n    print(\"\\n\")\n    print(f\"Total val-loss in this epoch: {valid_loss}\")\n    print(f\"Number of samples in this val-epoch: {len(train_loader.dataset)}\")\n    print(f\"Average val-loss in this epoch: {average_valid_loss}\")\n    print(\"######################################\")\n    print(\"\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-08-01T19:49:15.231414Z","iopub.execute_input":"2023-08-01T19:49:15.232153Z","iopub.status.idle":"2023-08-01T19:50:36.21567Z","shell.execute_reply.started":"2023-08-01T19:49:15.23212Z","shell.execute_reply":"2023-08-01T19:50:36.214329Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Training:  60%|█████████████████████              | 3/5 [00:03<00:01,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 1/5\nTotal loss in this batch: 22173.346710205078\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.3097236156463623\n\n\nTrain Batch: 2/5\nTotal loss in this batch: 22143.852996826172\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.3066513538360596\n\n\nTrain Batch: 3/5\nTotal loss in this batch: 22135.28594970703\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.3057589530944824\n\n\nTrain Batch: 4/5\nTotal loss in this batch: 22120.703887939453\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.3042399883270264\n\n\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|███████████████████████████████████| 5/5 [00:05<00:00,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 5/5\nTotal loss in this batch: 22105.531311035156\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.302659511566162\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nValidating: 100%|█████████████████████████████████| 2/2 [00:02<00:00,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"Val Batch: 1/2\nTotal val-loss in this batch: 22082.379913330078\nNumber of samples in this val-batch: 9600\nAverage val-loss per sample in this val-batch: 2.30024790763855\n\n\nVal Batch: 2/2\nTotal val-loss in this batch: 5514.0363693237305\nNumber of samples in this val-batch: 2400\nAverage val-loss per sample in this val-batch: 2.2975151538848877\n\n\n\n######################################\nEpoch: 1 / 10\nTotal loss in this epoch: 110678.72085571289\nNumber of samples in this train-epoch: 48000\nAverage loss in this epoch: 2.3058066844940184\n\n\nTotal val-loss in this epoch: 27596.41628265381\nNumber of samples in this val-epoch: 48000\nAverage val-loss in this epoch: 2.2997013568878173\n######################################\n\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nTraining:  60%|█████████████████████              | 3/5 [00:04<00:02,  1.06s/it]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 1/5\nTotal loss in this batch: 22095.146942138672\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.3015778064727783\n\n\nTrain Batch: 2/5\nTotal loss in this batch: 22067.813873291016\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2987306118011475\n\n\nTrain Batch: 3/5\nTotal loss in this batch: 22055.982971191406\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2974982261657715\n\n\nTrain Batch: 4/5\nTotal loss in this batch: 22035.626220703125\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.295377731323242\n\n\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|███████████████████████████████████| 5/5 [00:05<00:00,  1.18s/it]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 5/5\nTotal loss in this batch: 22025.592041015625\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.294332504272461\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nValidating: 100%|█████████████████████████████████| 2/2 [00:02<00:00,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Val Batch: 1/2\nTotal val-loss in this batch: 22006.640625\nNumber of samples in this val-batch: 9600\nAverage val-loss per sample in this val-batch: 2.2923583984375\n\n\nVal Batch: 2/2\nTotal val-loss in this batch: 5495.083236694336\nNumber of samples in this val-batch: 2400\nAverage val-loss per sample in this val-batch: 2.2896180152893066\n\n\n\n######################################\nEpoch: 2 / 10\nTotal loss in this epoch: 110280.16204833984\nNumber of samples in this train-epoch: 48000\nAverage loss in this epoch: 2.29750337600708\n\n\nTotal val-loss in this epoch: 27501.723861694336\nNumber of samples in this val-epoch: 48000\nAverage val-loss in this epoch: 2.291810321807861\n######################################\n\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nTraining:  60%|█████████████████████              | 3/5 [00:03<00:01,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 1/5\nTotal loss in this batch: 22008.83560180664\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2925870418548584\n\n\nTrain Batch: 2/5\nTotal loss in this batch: 22009.72137451172\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2926793098449707\n\n\nTrain Batch: 3/5\nTotal loss in this batch: 21980.45196533203\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.28963041305542\n\n\nTrain Batch: 4/5\nTotal loss in this batch: 21972.676849365234\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.288820505142212\n\n\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|███████████████████████████████████| 5/5 [00:05<00:00,  1.08s/it]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 5/5\nTotal loss in this batch: 21947.122192382812\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.286158561706543\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nValidating: 100%|█████████████████████████████████| 2/2 [00:02<00:00,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Val Batch: 1/2\nTotal val-loss in this batch: 21938.660430908203\nNumber of samples in this val-batch: 9600\nAverage val-loss per sample in this val-batch: 2.2852771282196045\n\n\nVal Batch: 2/2\nTotal val-loss in this batch: 5477.994346618652\nNumber of samples in this val-batch: 2400\nAverage val-loss per sample in this val-batch: 2.2824976444244385\n\n\n\n######################################\nEpoch: 3 / 10\nTotal loss in this epoch: 109918.80798339844\nNumber of samples in this train-epoch: 48000\nAverage loss in this epoch: 2.289975166320801\n\n\nTotal val-loss in this epoch: 27416.654777526855\nNumber of samples in this val-epoch: 48000\nAverage val-loss in this epoch: 2.2847212314605714\n######################################\n\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nTraining:  60%|█████████████████████              | 3/5 [00:03<00:01,  1.04it/s]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 1/5\nTotal loss in this batch: 21944.583892822266\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2858941555023193\n\n\nTrain Batch: 2/5\nTotal loss in this batch: 21936.646270751953\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.285067319869995\n\n\nTrain Batch: 3/5\nTotal loss in this batch: 21917.935180664062\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.28311824798584\n\n\nTrain Batch: 4/5\nTotal loss in this batch: 21891.261291503906\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2803397178649902\n\n\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|███████████████████████████████████| 5/5 [00:05<00:00,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 5/5\nTotal loss in this batch: 21898.418426513672\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.281085252761841\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nValidating: 100%|█████████████████████████████████| 2/2 [00:02<00:00,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Val Batch: 1/2\nTotal val-loss in this batch: 21874.793243408203\nNumber of samples in this val-batch: 9600\nAverage val-loss per sample in this val-batch: 2.2786242961883545\n\n\nVal Batch: 2/2\nTotal val-loss in this batch: 5461.96231842041\nNumber of samples in this val-batch: 2400\nAverage val-loss per sample in this val-batch: 2.275817632675171\n\n\n\n######################################\nEpoch: 4 / 10\nTotal loss in this epoch: 109588.84506225586\nNumber of samples in this train-epoch: 48000\nAverage loss in this epoch: 2.283100938796997\n\n\nTotal val-loss in this epoch: 27336.755561828613\nNumber of samples in this val-epoch: 48000\nAverage val-loss in this epoch: 2.2780629634857177\n######################################\n\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nTraining:  60%|█████████████████████              | 3/5 [00:03<00:01,  1.04it/s]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 1/5\nTotal loss in this batch: 21878.64761352539\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2790257930755615\n\n\nTrain Batch: 2/5\nTotal loss in this batch: 21875.4638671875\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2786941528320312\n\n\nTrain Batch: 3/5\nTotal loss in this batch: 21861.2548828125\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2772140502929688\n\n\nTrain Batch: 4/5\nTotal loss in this batch: 21834.290313720703\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2744052410125732\n\n\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|███████████████████████████████████| 5/5 [00:05<00:00,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 5/5\nTotal loss in this batch: 21821.575927734375\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.273080825805664\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nValidating: 100%|█████████████████████████████████| 2/2 [00:02<00:00,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Val Batch: 1/2\nTotal val-loss in this batch: 21811.81182861328\nNumber of samples in this val-batch: 9600\nAverage val-loss per sample in this val-batch: 2.272063732147217\n\n\nVal Batch: 2/2\nTotal val-loss in this batch: 5445.990943908691\nNumber of samples in this val-batch: 2400\nAverage val-loss per sample in this val-batch: 2.269162893295288\n\n\n\n######################################\nEpoch: 5 / 10\nTotal loss in this epoch: 109271.23260498047\nNumber of samples in this train-epoch: 48000\nAverage loss in this epoch: 2.2764840126037598\n\n\nTotal val-loss in this epoch: 27257.802772521973\nNumber of samples in this val-epoch: 48000\nAverage val-loss in this epoch: 2.271483564376831\n######################################\n\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nTraining:  60%|█████████████████████              | 3/5 [00:04<00:02,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 1/5\nTotal loss in this batch: 21820.182037353516\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.272935628890991\n\n\nTrain Batch: 2/5\nTotal loss in this batch: 21803.814697265625\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.271230697631836\n\n\nTrain Batch: 3/5\nTotal loss in this batch: 21781.56509399414\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2689130306243896\n\n\nTrain Batch: 4/5\nTotal loss in this batch: 21782.276916503906\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2689871788024902\n\n\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|███████████████████████████████████| 5/5 [00:06<00:00,  1.22s/it]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 5/5\nTotal loss in this batch: 21764.513397216797\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.267136812210083\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nValidating: 100%|█████████████████████████████████| 2/2 [00:02<00:00,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"Val Batch: 1/2\nTotal val-loss in this batch: 21747.750091552734\nNumber of samples in this val-batch: 9600\nAverage val-loss per sample in this val-batch: 2.265390634536743\n\n\nVal Batch: 2/2\nTotal val-loss in this batch: 5429.621887207031\nNumber of samples in this val-batch: 2400\nAverage val-loss per sample in this val-batch: 2.2623424530029297\n\n\n\n######################################\nEpoch: 6 / 10\nTotal loss in this epoch: 108952.35214233398\nNumber of samples in this train-epoch: 48000\nAverage loss in this epoch: 2.269840669631958\n\n\nTotal val-loss in this epoch: 27177.371978759766\nNumber of samples in this val-epoch: 48000\nAverage val-loss in this epoch: 2.2647809982299805\n######################################\n\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nTraining:  60%|█████████████████████              | 3/5 [00:03<00:01,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 1/5\nTotal loss in this batch: 21751.670837402344\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.265799045562744\n\n\nTrain Batch: 2/5\nTotal loss in this batch: 21745.667266845703\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2651736736297607\n\n\nTrain Batch: 3/5\nTotal loss in this batch: 21731.009674072266\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2636468410491943\n\n\nTrain Batch: 4/5\nTotal loss in this batch: 21704.470825195312\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2608823776245117\n\n\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|███████████████████████████████████| 5/5 [00:05<00:00,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 5/5\nTotal loss in this batch: 21692.564392089844\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2596421241760254\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nValidating: 100%|█████████████████████████████████| 2/2 [00:02<00:00,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Val Batch: 1/2\nTotal val-loss in this batch: 21681.44989013672\nNumber of samples in this val-batch: 9600\nAverage val-loss per sample in this val-batch: 2.258484363555908\n\n\nVal Batch: 2/2\nTotal val-loss in this batch: 5412.569618225098\nNumber of samples in this val-batch: 2400\nAverage val-loss per sample in this val-batch: 2.255237340927124\n\n\n\n######################################\nEpoch: 7 / 10\nTotal loss in this epoch: 108625.38299560547\nNumber of samples in this train-epoch: 48000\nAverage loss in this epoch: 2.2630288124084474\n\n\nTotal val-loss in this epoch: 27094.019508361816\nNumber of samples in this val-epoch: 48000\nAverage val-loss in this epoch: 2.257834959030151\n######################################\n\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nTraining:  60%|█████████████████████              | 3/5 [00:03<00:01,  1.03it/s]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 1/5\nTotal loss in this batch: 21688.357543945312\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2592039108276367\n\n\nTrain Batch: 2/5\nTotal loss in this batch: 21662.928771972656\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2565550804138184\n\n\nTrain Batch: 3/5\nTotal loss in this batch: 21657.614135742188\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2560014724731445\n\n\nTrain Batch: 4/5\nTotal loss in this batch: 21665.453338623047\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2568180561065674\n\n\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|███████████████████████████████████| 5/5 [00:05<00:00,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 5/5\nTotal loss in this batch: 21610.80551147461\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2511255741119385\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nValidating: 100%|█████████████████████████████████| 2/2 [00:02<00:00,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Val Batch: 1/2\nTotal val-loss in this batch: 21612.30926513672\nNumber of samples in this val-batch: 9600\nAverage val-loss per sample in this val-batch: 2.251282215118408\n\n\nVal Batch: 2/2\nTotal val-loss in this batch: 5394.72541809082\nNumber of samples in this val-batch: 2400\nAverage val-loss per sample in this val-batch: 2.247802257537842\n\n\n\n######################################\nEpoch: 8 / 10\nTotal loss in this epoch: 108285.15930175781\nNumber of samples in this train-epoch: 48000\nAverage loss in this epoch: 2.255940818786621\n\n\nTotal val-loss in this epoch: 27007.03468322754\nNumber of samples in this val-epoch: 48000\nAverage val-loss in this epoch: 2.250586223602295\n######################################\n\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nTraining:  60%|█████████████████████              | 3/5 [00:03<00:01,  1.05it/s]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 1/5\nTotal loss in this batch: 21619.608306884766\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.252042531967163\n\n\nTrain Batch: 2/5\nTotal loss in this batch: 21599.08218383789\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2499043941497803\n\n\nTrain Batch: 3/5\nTotal loss in this batch: 21581.332397460938\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2480554580688477\n\n\nTrain Batch: 4/5\nTotal loss in this batch: 21578.1005859375\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2477188110351562\n\n\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|███████████████████████████████████| 5/5 [00:05<00:00,  1.10s/it]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 5/5\nTotal loss in this batch: 21551.962280273438\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2449960708618164\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nValidating: 100%|█████████████████████████████████| 2/2 [00:02<00:00,  1.12s/it]","output_type":"stream"},{"name":"stdout","text":"Val Batch: 1/2\nTotal val-loss in this batch: 21540.12680053711\nNumber of samples in this val-batch: 9600\nAverage val-loss per sample in this val-batch: 2.2437632083892822\n\n\nVal Batch: 2/2\nTotal val-loss in this batch: 5376.047515869141\nNumber of samples in this val-batch: 2400\nAverage val-loss per sample in this val-batch: 2.2400197982788086\n\n\n\n######################################\nEpoch: 9 / 10\nTotal loss in this epoch: 107930.08575439453\nNumber of samples in this train-epoch: 48000\nAverage loss in this epoch: 2.248543453216553\n\n\nTotal val-loss in this epoch: 26916.17431640625\nNumber of samples in this val-epoch: 48000\nAverage val-loss in this epoch: 2.2430145263671877\n######################################\n\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nTraining:  60%|█████████████████████              | 3/5 [00:04<00:02,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 1/5\nTotal loss in this batch: 21531.731414794922\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2428886890411377\n\n\nTrain Batch: 2/5\nTotal loss in this batch: 21541.65802001953\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.243922710418701\n\n\nTrain Batch: 3/5\nTotal loss in this batch: 21513.97933959961\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.241039514541626\n\n\nTrain Batch: 4/5\nTotal loss in this batch: 21492.597198486328\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.238812208175659\n\n\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|███████████████████████████████████| 5/5 [00:05<00:00,  1.19s/it]","output_type":"stream"},{"name":"stdout","text":"Train Batch: 5/5\nTotal loss in this batch: 21479.017639160156\nNumber of samples in this batch: 9600\nAverage loss per sample in this batch: 2.2373976707458496\n\n\n","output_type":"stream"},{"name":"stderr","text":"\nValidating: 100%|█████████████████████████████████| 2/2 [00:02<00:00,  1.09s/it]","output_type":"stream"},{"name":"stdout","text":"Val Batch: 1/2\nTotal val-loss in this batch: 21464.65301513672\nNumber of samples in this val-batch: 9600\nAverage val-loss per sample in this val-batch: 2.235901355743408\n\n\nVal Batch: 2/2\nTotal val-loss in this batch: 5356.418609619141\nNumber of samples in this val-batch: 2400\nAverage val-loss per sample in this val-batch: 2.2318410873413086\n\n\n\n######################################\nEpoch: 10 / 10\nTotal loss in this epoch: 107558.98361206055\nNumber of samples in this train-epoch: 48000\nAverage loss in this epoch: 2.240812158584595\n\n\nTotal val-loss in this epoch: 26821.07162475586\nNumber of samples in this val-epoch: 48000\nAverage val-loss in this epoch: 2.2350893020629883\n######################################\n\n\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f\"Total time model run in each epochs :{model_run_count}\")\nprint(f\"Total batches in train loader: {len(train_loader)}\")\nprint(f\"Total batches in train loader: {len(val_loader)}\")\nprint(f\"Total epochs: {n_epochs}\")\nprint(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-08-01T19:50:36.218106Z","iopub.execute_input":"2023-08-01T19:50:36.218576Z","iopub.status.idle":"2023-08-01T19:50:36.226563Z","shell.execute_reply.started":"2023-08-01T19:50:36.218528Z","shell.execute_reply":"2023-08-01T19:50:36.225498Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Total time model run in each epochs :70\nTotal batches in train loader: 5\nTotal batches in train loader: 2\nTotal epochs: 10\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---\n## Test the Trained Network\n\nFinally, we test our best model on previously unseen **test data** and evaluate it's performance. Testing on unseen data is a good way to check that our model generalizes well. It may also be useful to be granular in this analysis and take a look at how this model performs on each class as well as looking at its overall loss and accuracy.\n\n#### `model.eval()`\n\n`model.eval(`) will set all the layers in your model to evaluation mode. This affects layers like dropout layers that turn \"off\" nodes during training with some probability, but should allow every node to be \"on\" for evaluation!","metadata":{}},{"cell_type":"code","source":"test_loss = 0\nclass_correct = list(0.0 for i in range(10))\nclass_total = list(0.0 for i in range(10))\n\nmodel.eval()\n\nfor batch_idx, (data, target) in tqdm(\n                            enumerate(test_loader),\n                            desc=\"Testing\",\n                            total=len(test_loader),\n                            leave=True,\n                            ncols=80):\n    \n    output = model(data)\n    \n    loss = criterion(output, target)    \n    test_loss += loss.item()*data.size(0)\n    \n    _, pred = torch.max(output, 1)\n\n    for i in range(target.shape[0]):\n        label = target[i]\n        class_correct[label] += (1 if pred[i].item() == label else 0)\n        class_total[label] += 1\n        \navergae_test_loss = test_loss / len(test_loader.dataset)\nprint(f\"Average test-loss: {avergae_train_loss}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-01T19:50:36.228549Z","iopub.execute_input":"2023-08-01T19:50:36.228992Z","iopub.status.idle":"2023-08-01T19:50:38.629787Z","shell.execute_reply.started":"2023-08-01T19:50:36.228952Z","shell.execute_reply":"2023-08-01T19:50:38.628549Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Testing: 100%|████████████████████████████████████| 2/2 [00:02<00:00,  1.14s/it]","output_type":"stream"},{"name":"stdout","text":"Average test-loss: 2.240812158584595\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in range(10):\n    if class_total[i] > 0:\n        print(f\"Accuracy of {i}: {100*class_correct[i]/class_total[i]} ({class_correct[i]}/{class_total[i]})\")\n    else:\n        print(f\"Accuracy of {i}: N/A (no training examples)\")\n        \nprint(f\"\\nOverall Accuracy: {100 * sum(class_correct)/ sum(class_total)}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-01T19:52:10.940287Z","iopub.execute_input":"2023-08-01T19:52:10.9407Z","iopub.status.idle":"2023-08-01T19:52:10.947399Z","shell.execute_reply.started":"2023-08-01T19:52:10.940667Z","shell.execute_reply":"2023-08-01T19:52:10.946286Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Accuracy of 0: 56.734693877551024 (556.0/980.0)\nAccuracy of 1: 96.74008810572687 (1098.0/1135.0)\nAccuracy of 2: 9.496124031007753 (98.0/1032.0)\nAccuracy of 3: 55.742574257425744 (563.0/1010.0)\nAccuracy of 4: 7.2301425661914465 (71.0/982.0)\nAccuracy of 5: 0.0 (0.0/892.0)\nAccuracy of 6: 0.0 (0.0/958.0)\nAccuracy of 7: 75.68093385214007 (778.0/1028.0)\nAccuracy of 8: 15.91375770020534 (155.0/974.0)\nAccuracy of 9: 22.497522299306244 (227.0/1009.0)\n\nOverall Accuracy: 35.46\n","output_type":"stream"}]}]}