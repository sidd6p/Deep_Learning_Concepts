{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/siddp6/mnist-classification?scriptVersionId=139202723\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Multi-Layer Perceptron, MNIST\n---\n\nThis notebook aims to demonstrate the training of a Multi-Layer Perceptron (MLP) for the classification of images from the [MNIST database](http://yann.lecun.com/exdb/mnist/), which contains hand-written digits.\n\nThe process can be broken down into the following sequential steps:\n\n1. **Loading and Visualizing the Data**\n   We begin by loading the dataset and visualizing some samples.\n\n2. **Defining the Neural Network**\n   The architecture of the MLP is defined in this step.\n\n3. **Training the Model**\n   The MLP model is trained using the dataset.\n\n4. **Evaluating Model Performance**\n   We assess the performance of the trained model using a separate test dataset.\n\nBefore we start, we need to import the required libraries for data manipulation, PyTorch, and additional utilities.\n","metadata":{}},{"cell_type":"code","source":"import torch  # Importing the PyTorch library for tensor computations and machine learning\nimport multiprocessing  # Importing the multiprocessing module for parallel processing\nimport numpy as np  # Importing the NumPy library for numerical computations\nfrom tqdm import tqdm  # Importing the tqdm library for creating progress bars in loops","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n## Load and Visualize the [Data](http://pytorch.org/docs/stable/torchvision/datasets.html)\n\nDownloading may take a few moments, and you should see your progress as the data is loading. You may also choose to change the `batch_size` if you want to load more data at a time.\n\nThis cell will create DataLoaders for each of our datasets.","metadata":{}},{"cell_type":"code","source":"from torchvision import datasets\nimport torchvision.transforms as transforms\n\n# number of sub-process to load the data\n# set to the number of CPUs avaliable\nnum_workers = multiprocessing.cpu_count()\n\n# number of sample per batch ot load\nbatch_size = 64\n\ntransform = transforms.Compose([\n    # input: np.array or PIL image with range 0-255\n    # transform: float tensor with range 0.0 - 1.0\n    transforms.ToTensor(),\n    \n    # transform: float tensor with range -1.0 - 1.0\n    # (better for activation like Relu)\n    transforms.Normalize((0.5), (0.5)),\n])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the MNIST dataset for training/validation.\ntrain_val_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the specific context of the code snippet you provided, `torch.utils.data.random_split()` uses the random number generator (`generator`) to perform the random split of the dataset (`train_val_data`). By setting the same fixed seed (42) each time the code runs, the split will be consistent and reproducible across different runs.\n\nFor example, if you run the script multiple times with the same seed (42), you will get the same training and validation subsets split from the `train_val_data`, making it easier to compare results and analyze model performance.\n","metadata":{}},{"cell_type":"code","source":"# Splitting the dataset into training and validation subsets\ntrain_len = int(len(train_val_data) * 0.80)  # 80% for training\nval_len = int(len(train_val_data) * 0.20)   # 20% for validation\n\n# Randomly splitting the dataset using a fixed seed for reproducibility\ntrain_subset, val_subset = torch.utils.data.random_split(\n    train_val_data, [train_len, val_len], generator=torch.Generator().manual_seed(42)\n)\n\n# Creating data loaders for training and validation\ntrain_loader = torch.utils.data.DataLoader(\n    dataset=train_subset, shuffle=True, batch_size=batch_size, num_workers=num_workers\n)\n\nval_loader = torch.utils.data.DataLoader(\n    dataset=val_subset, shuffle=False, batch_size=batch_size, num_workers=num_workers\n)\n# num_workers: The number of subprocesses to use for data loading.\n# It can speed up data loading by parallelizing the loading process.\n# Set it to a higher value if you have multiple CPU cores available.\n# However, setting it too high might lead to memory issues, so find a balance.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get test data using MNIST dataset\ntest_data = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n\n# Create a data loader for test data\ntest_loader = torch.utils.data.DataLoader(\n    test_data, batch_size=batch_size, num_workers=num_workers\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Data: {len(train_val_data)}\")\nprint(f\"Data for train: {len(train_subset)}\")\nprint(f\"Total batches in train loader: {len(train_loader)}\")\nprint(f\"Total images in one batch: {len(train_subset)/len(train_loader)}\")\nprint(\"\\n\")\n\nbatch_1 = next(iter(train_loader))\nprint(f\"Each batch has {len(batch_1)} component, image and label\")\nprint(\"\\n\")\n\nprint(f\"First component has {len(batch_1[0])} images\")\nprint(f\"Second component has {len(batch_1[1])} labels\")\nprint(f\"Shape of first component of each batch {batch_1[0].shape}\")\nprint(f\"Shape of second component of each batch {batch_1[1].shape}\")\n\nprint(\"\\n\")\n\n\n# print(f\"First image from first batch is {batch_1[0][0]} and lable is {batch_1[1][0]}\")\n\nprint(f\"Shape of Image: {batch_1[0][0].shape}\")\nprint(f\"Shape of Label: {batch_1[1][0].shape}\")\nprint(f\"Shape of Image after view function {batch_1[0][0].view(-1, 28*28).shape}\")\nprint(\"\\n\")\n\n\nprint(len(train_loader.dataset))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n## Define the Network [Architecture](http://pytorch.org/docs/stable/nn.html)\n\n\nThe architecture will be responsible for seeing as input a 784-dim Tensor of pixel values for each image, and producing a Tensor of length 10 (our number of classes) that indicates the class scores for an input image. This particular example uses two hidden layers and dropout to avoid overfitting.\n\n[For mode detail](https://ashwinhprasad.medium.com/pytorch-for-deep-learning-nn-linear-and-nn-relu-explained-77f3e1007dbb)","metadata":{}},{"cell_type":"markdown","source":"The `model_run_count` variable is used to keep track of how many times the `forward` method of the `Net` neural network model is executed. \n\n- **Monitoring Progress:** During the training phase of a neural network, you might want to keep track of how many times the model's forward pass is performed to have an idea of the total number of iterations or epochs completed. This information can be used for monitoring the progress of the training process.\n\nIn summary, `model_run_count` serves as a counter to keep track of the usage of the neural network model and can be leveraged to implement various behaviors and monitoring strategies during training or inference.\n","metadata":{}},{"cell_type":"code","source":"model_run_count = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\n\n# Define a neural network class called 'Net' that inherits from nn.Module\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()  # Initialize the parent class constructor\n        self.layer_1 = nn.Linear(784, 128)  \n        self.layer_2 = nn.Linear(128, 64)  \n        self.layer_3 = nn.Linear(64, 10)    \n        \n        self.Relu = nn.ReLU()  # ReLU activation function instance\n\n    # Define the forward pass of the neural network\n    def forward(self, X):\n        global model_run_count\n        model_run_count += 1  # Increment the global variable 'model_run_count' to track how many times the model is run\n        X = X.view(-1, 28*28)  # Reshape the input tensor to have a size of (-1, 784)\n        X = self.Relu(self.layer_1(X))  \n        X = self.Relu(self.layer_2(X))  \n        X = self.layer_3(X) \n        \n        return X  # Return the final output tensor","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Net()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## (Bonus: visualize the structure of your network)\nYou can visualize your achitecture by using netron.app. Just execute the following cell (which will save the network to a file called \"mnist_network.pt\" in this directory), then download the produced `mnist_network.pt` to your computer. Finally, go to [Netron.app](https://netron.app) and click on `Open Model`, and select the file you just downloaded.","metadata":{}},{"cell_type":"markdown","source":"**Comment model_run_count in ```forward``` before running next cell**","metadata":{}},{"cell_type":"code","source":"# scripted = torch.jit.script(model)\n# torch.jit.save(scripted, \"Net.pt\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define loss and optimizer\n\n1. `criterion = nn.CrossEntropyLoss()`: \n   - The `CrossEntropyLoss` is a loss function used for multi-class classification tasks.\n   - It combines the softmax activation and the negative log-likelihood loss.\n   - It is suitable for problems where each input belongs to one class among multiple classes.\n\n2. `optimizer = torch.optim.SGD(model.parameters(), lr=0.01)`: \n   - The `SGD` optimizer is used to update the model's parameters during training.\n   - It performs stochastic gradient descent, which updates the parameters based on gradients of the loss.\n   - `model.parameters()` provides the parameters (weights and biases) of the model to be optimized.\n   - `lr=0.01` sets the learning rate, which controls the step size during parameter updates.","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=.01)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n## Train the Network\n\nThe steps for training/learning from a batch of data are described in the comments below:\n1. Clear the gradients of all optimized variables\n2. Forward pass: compute predicted outputs by passing inputs to the model\n3. Calculate the loss\n4. Backward pass: compute gradient of the loss with respect to model parameters\n5. Perform a single optimization step (parameter update)\n6. Update average training loss","metadata":{}},{"cell_type":"code","source":"!pip install livelossplot","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# This is a plotting function\ndef after_subplot(ax: plt.Axes, group_name: str, x_label: str):\n    \"\"\"Add title xlabel and legend to single chart\"\"\"\n    ax.set_title(group_name)\n    ax.set_xlabel(x_label)\n    ax.legend(loc=\"center right\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\nfrom livelossplot import PlotLosses  # Live plot for training loss visualization\nfrom livelossplot.outputs import MatplotlibPlot  # Output type for livelossplot\n\n# Number of epochs to train the model\nn_epochs = 100  # Suggested training between 20-100 epochs\nmodel_run_count = 0  # Counter for model runs (not used in the code)\nmodel.train()  # Set the model in training mode\nliveloss = PlotLosses(outputs=[MatplotlibPlot(after_subplot=after_subplot)])  # Initialize live loss plot\nlogs = {}  # Dictionary to store training and validation loss\n\n# Loop through each epoch with tqdm (progress bar)\nfor epoch in tqdm(\n            range(n_epochs),\n            desc=\"Epochs\",\n            total=n_epochs,\n            leave=True,\n            ncols=80,\n        ):\n    # Initialize training loss for the current epoch\n    train_loss = 0.0\n    \n    ###################\n    # Train the model #\n    ###################\n    for batch_idx, (data, target) in enumerate(train_loader):\n        \n        # Clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        \n        # Forward pass: Compute predicted outputs by passing inputs to the model\n        output = model(data)\n        \n        # Calculate the loss\n        loss = criterion(output, target)\n        \n        # Backward pass: Compute gradient of the loss with respect to model parameters\n        loss.backward()\n        \n        # Perform a single optimization step (parameter update)\n        optimizer.step()\n        \n        # Update running training loss\n        train_loss += loss.item() * data.size(0)\n\n    # Calculate average loss over an epoch\n    average_train_loss = train_loss / len(train_loader.dataset)\n    \n    # Validate\n    with torch.no_grad():\n        # Set the model to evaluation mode\n        model.eval()\n\n        # Initialize validation loss for the current epoch\n        valid_loss = 0.0\n        for batch_idx, (data, target) in enumerate(val_loader):\n            \n            # 1. Forward pass: Compute predicted outputs by passing inputs to the model\n            output = model(data)\n            # 2. Calculate the loss\n            loss = criterion(output, target)\n            \n            # Update running validation loss\n            valid_loss += loss.item() * data.size(0)\n\n        # Calculate average validation loss\n        average_valid_loss = valid_loss / len(val_loader.dataset)\n    \n    # Update logs dictionary with training and validation loss\n    logs['loss'] = average_train_loss\n    logs['val_loss'] = average_valid_loss\n    \n    # Update and visualize live loss plot\n    liveloss.update(logs)\n    liveloss.send()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"A: Total time model run in each epochs :{model_run_count}\")\nprint(f\"B: Total batches in train loader: {len(train_loader)}\")\nprint(f\"C: Total batches in train loader: {len(val_loader)}\")\nprint(f\"D: Total epochs: {n_epochs}\")\nprint(\"A = (B + C) * D\")\nprint(\"\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n## Test the Trained Network\n\nFinally, we test our best model on previously unseen **test data** and evaluate it's performance. Testing on unseen data is a good way to check that our model generalizes well. It may also be useful to be granular in this analysis and take a look at how this model performs on each class as well as looking at its overall loss and accuracy.\n\n#### `model.eval()`\n\n`model.eval(`) will set all the layers in your model to evaluation mode. This affects layers like dropout layers that turn \"off\" nodes during training with some probability, but should allow every node to be \"on\" for evaluation!","metadata":{}},{"cell_type":"code","source":"# Initialize variables to keep track of test loss, correct predictions per class, and total instances per class.\ntest_loss = 0\nclass_correct = list(0.0 for i in range(10))\nclass_total = list(0.0 for i in range(10))\n\n# Set the model to evaluation mode, disabling certain operations like dropout.\nmodel.eval()\n\n# Iterate through the test_loader using tqdm for progress visualization.\nfor batch_idx, (data, target) in tqdm(\n                        enumerate(test_loader),\n                        desc=\"Testing\",\n                        total=len(test_loader),\n                        leave=True,\n                        ncols=80):\n\n    # Forward pass: compute predicted outputs by passing input data through the model.\n    output = model(data)\n\n    # Calculate the loss between the model's output and the actual target labels.\n    loss = criterion(output, target)\n    # Accumulate the test loss, weighted by the number of data instances in the batch.\n    test_loss += loss.item() * data.size(0)\n\n    # Find the predicted class indices with the highest scores for each data instance.\n    _, pred = torch.max(output, 1)\n\n    # Iterate through each target label and update the class_correct and class_total counts.\n    for i in range(target.shape[0]):\n        label = target[i]\n        # If the predicted class matches the target class, increment class_correct for that class.\n        class_correct[label] += (1 if pred[i].item() == label else 0)\n        # Increment class_total for the target class, regardless of prediction correctness.\n        class_total[label] += 1\n\n# Calculate the average test loss by dividing the accumulated test loss by the dataset size.\naverage_test_loss = test_loss / len(test_loader.dataset)\n# Print the calculated average test loss.\nprint(f\"Average test-loss: {average_test_loss}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loop through the range of values from 0 to 9\nfor i in range(10):\n    # Check if there are any training examples for the current class\n    if class_total[i] > 0:\n        # Calculate the accuracy percentage for the current class and print the result\n        print(f\"Accuracy of {i}: {100 * class_correct[i] / class_total[i]} ({class_correct[i]}/{class_total[i]})\")\n    else:\n        # If no training examples for the current class, print N/A\n        print(f\"Accuracy of {i}: N/A (no training examples)\")\n\n# Calculate and print the overall accuracy percentage across all classes\nprint(f\"\\nOverall Accuracy: {100 * sum(class_correct) / sum(class_total)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}